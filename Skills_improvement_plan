docker plan:
1) docs (file systems (overlay fs))
2) dockerfile (run, entry point, cmd) (layewrs) (try to wright few files)
3) commands (docker run ssh)
4) run docker (with jenkins) connect file transfer network
5) check network betwenn containers
6) docker compose
7) touch docker swarm (probalby use for deploy) --going to die
8) volumes - connect hosts folders
9) try to use diff versdions for jenkinsd ( jobs on host folder)
10)loging (docker logs)

also:
  jenkins try catch
aws
network , users,
monitoring
terraform - easy (1 week)
prometheus
serverless (лямбда)

mionitoring elk efk ()
kuber
nginx tomcat appache

Linux administration techotrack
(1 hz;2the best ;3 -dns,dig,network TROUBLESHOOTING watch on rewind;4 RPMBUILD,init,systemd;5 theory web srvs(queryies)DB HZ);6 mbr-gpt\raid\lvm\ext4;
7 dns-bind configuration\ntp\pam\ldap auth\dhcp\kickstart;8-9 SALT\backup\bacula;10 smtp\postfix;11 os resource


docker notes:
--Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers.
        The use of Linux containers to deploy applications is called containerization.
--docker run as client-server.The Docker daemon (dockerd) listens for Docker API requests and manages Docker objects
        such as images, containers, networks, and volumes. When you use commands such as docker run, the client sends these commands to dockerd,
        which carries them out. The docker command uses the Docker API.
--Docker registry stores Docker images. Docker Hub and Docker Cloud are public registries that anyone can use.
        You can even run your own private registry.
--An image is an executable package that includes everything needed to run an application--the code, a runtime,
        libraries, environment variables, and configuration files.
        An image is a read-only template with instructions for creating a Docker container.
        Often, an image is based on another image, with some additional customization.
        A Docker image is built up from a series of layers. Each layer represents an instruction in the image’s Dockerfile.
        Each layer except the very last one is read-only.Each layer is only a set of differences from the layer before it.
        The layers are stacked on top of each other. When you create a new container, you add a new writable layer on top of the underlying layers.
        This layer is often called the “container layer”. All changes made to the running container, such as writing new files,
        modifying existing files, and deleting files, are written to this thin writable container layer.
--A container is a runnable instance of an image. You can create, start, stop, move, or delete a container using the Docker API or CLI.
        You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state.
        Container take by default ip addresses from dhcp pull
--docker image and docker container have their own ID and NAME
--The major difference between a container and an image is the top writable layer.
        All writes to the container that add new or modify existing data are stored in this writable layer.
        When the container is deleted, the writable layer is also deleted. The underlying image remains unchanged.
--A storage driver handles the details about the way these layers interact with each other.
        Different storage drivers are available, which have advantages and disadvantages in different situations.
        Docker uses storage drivers to manage the contents of the image layers and the writable container layer.
        Each storage driver handles the implementation differently, but all drivers use stackable image layers
        and the copy-on-write (CoW) strategy.Copy-on-write is a strategy of sharing and copying files for maximum efficiency.
        If a file or directory exists in a lower layer within the image, and another layer (including the writable layer) needs read access to it,
        it just uses the existing file. The first time another layer needs to modify the file (when building the image or running the container)
        the file is copied into that layer and modified. This minimizes I/O and the size of each of the subsequent layers.
--Note If you need multiple images to have shared access to the exact same data,
        store this data in a Docker volume and mount it into your containers.
--Ephemeral Containers - A container that immediately exits when finished.
--docker run standalone processes(not daemons cause dont have sysv\systemd utils for it)
--Dockerfile Creates an easy to read, easy to write, user base image.
        each command in Dockerfile build another container(layer) and take up additional space (better combine commands with &&)
        build with dockerfile will use cache if commands in dockerfile was previosly run(cahed steps)
        commands RUN(run command while building image);ENV(set variable with spaces);EXPOSE(port from container exposed but not passed through);
        CMD(run commands after container being run E.G.["command","arg1","arg2"])
--SWARM.Services allow you to scale containers across multiple Docker daemons, which all work together as a swarm with
        multiple managers and workers. Each member of a swarm is a Docker daemon, and the daemons all communicate using the Docker API.
        A service allows you to define the desired state, such as the number of replicas of the service that must be available at any given time.
        By default, the service is load-balanced across all worker nodes.
        To the consumer, the Docker service appears to be a single application.
--docker run -- run containers(or command inside)based on images
        (if run with "-it"you will connect to container but it will be shut after you will exit)
        ps list containers (-a all that been started before)
        pull - download image(snapshot) from dockerhub to local
        search --search images on dockerhub in terminal
        attach --attach terminal to the process that container is running(after ctrl+c will shut process and container)
        inspect --json about container
        exec --run command(E.G. /bin/bash) inside container (without connecting)exiting will not cause shutdown of the container
          -it interactivly connect to container (docker exec -it 'Container name' 'command') (cli inside container)
        --name to add my own name to the running container
        rm\rmi -remove container(rm)\image(rmi) (by ID or name). Can't remove images (without force "-f")if you have containers based on them.
        -d in background(disconnected)
        -e execute smth (-d-e The container will continue to run as long as the argument is running, as soon as the argument stops the container will exit.)
        ps -a -q shows IDs of all not currently not running containers(docker rm `docker ps -a -q`)
        -P all container ports forwarded to the local host though randomly picked local ports in the 32768 to 65000 range.Ports info at `docker ps`
        -p "local port":"containers port", -//-  bind local port with container port
        port (CONTAINER) $CONTAINERPORT -Will show the variable of the CONTAINERPORT which is the open ports of the container and the random port links to the local host.
        -v 'path to local dir':'path where to mount inside the container' to mount local dir in container(changes apply on the fly)
        build -t 'docker hub accout'/imagename '.(path to Dockerfile)'
 to install - add docker repo;install docker-engine;add user to docker group
